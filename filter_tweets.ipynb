{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "from functions.semantic_search import convert_glove, search_similar_words\n",
    "from functions.preprocessing import concat_tweet_files, filter_tweet_file, concat_btc_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the glove to the right format\n",
    "convert_glove('data/glove/glove.twitter.27B.200d.txt', 'data/glove/gensim_glove_vectors_twitter.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: This has to be ran multiple times for different words which the user finds to be often used when describing the topic.\n",
    "#       The words used for the BTC analysis were: crypto, cryptocurrency, currency, investment, speculate, stocks, trading\n",
    "#       Afterwards, relevant words were handpicked and written into a file called semantic_search_words.csv in column 1.\n",
    "#       Words which should NOT be contained in the tweets go into column 2\n",
    "\n",
    "wordlist = search_similar_words('data/glove/gensim_glove_vectors_twitter.txt', 'crypto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of all coins\n",
    "coinlist = ['ADA', 'BCH','BCN','BTC','DASH','EOS','ETC','ETH','ICX','IOT','LTC','NEO','QTUM','TRX','VEN','XEM','XLM','XMR','XRP','ZEC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter all coins in coinlist and print the length of the files after each step\n",
    "\n",
    "lengths = list()\n",
    "\n",
    "\n",
    "for f in coinlist:\n",
    "    df_tweets = concat_tweet_files(f)\n",
    "    df_tweets_filtered, lengths = filter_tweet_file(df_tweets, 'data/semantic_search_words.csv')\n",
    "    pd.DataFrame.to_csv(df_tweets_filtered, 'data/filtered_tweets/' + f + '_semantic_filtered.csv')\n",
    "    print(f)\n",
    "    print(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for BTC specifically since the scraping for BTC was done multiple times -> Include everything\n",
    "coinlist = ['BTC']\n",
    "df_tweets = concat_btc_files('BTC')\n",
    "df_tweets_filtered, lengths = filter_tweet_file(df_tweets, 'data/semantic_search_words.csv')\n",
    "pd.DataFrame.to_csv(df_tweets_filtered, 'data/filtered_tweets/' + f + '_semantic_filtered.csv')\n",
    "print(f)\n",
    "print(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all individual tweet scrape files into one giant file\n",
    "df_tweets = concat_tweet_files(coin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the tweet file by removing duplicates and filtering 'Text' to only keep rows if they contain one of the filter words\n",
    "df_tweets_filtered, len_list = filter_tweet_file(df_tweets, 'data/semantic_search_words.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the filtered file\n",
    "pd.DataFrame.to_csv(df_tweets_filtered, 'data/' + coin + '_semantic_filtered.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the Percentage of Tweets for each coin (unfinished)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_tweets = pd.read_csv('C:/Users/lukas/Dropbox/STUDIUM/Python/master_thesis/data/number_of_tweets_filtering.csv')\n",
    "number_of_tweets_sorted = number_of_tweets.sort_values('Unfiltered Tweets', ascending = False)\n",
    "number_of_tweets_sorted['share'] = number_of_tweets['Unfiltered Tweets']/np.sum(number_of_tweets['Unfiltered Tweets'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(range(len(number_of_tweets['Unfiltered Tweets'])), number_of_tweets_sorted['share'])\n",
    "plt.xlabel('Coin', fontsize=12)\n",
    "plt.ylabel('%', fontsize=12)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Sentiment Env)",
   "language": "python",
   "name": "sentiment_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
