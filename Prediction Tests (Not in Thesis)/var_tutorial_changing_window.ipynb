{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## UNFINISHED ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plot\n",
    "\n",
    "from load_data import load_financial_data, load_sentiment_data\n",
    "from preprocessing import calculate_financial_change, aggregate_sentiment, aggregate_financials, merge_sentiment_financials\n",
    "from statsmodels.tsa.vector_ar.vecm import coint_johansen\n",
    "from statsmodels.tsa.vector_ar.var_model import VAR\n",
    "from statsmodels.tsa.statespace.varmax import VARMAX\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from statsmodels.tsa.arima_model import ARMA\n",
    "from statsmodels.tsa.stattools import adfuller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tickers = ['ADA', 'BCH', 'BCN', 'BNB', 'BTC', 'DASH', 'EOS', 'ETC', 'ETH', 'ICX', 'IOT', 'LTC', 'NEO', 'QTUM',\n",
    "#               'TRON', 'VEN', 'XEM', 'XLM', 'XMR', 'XRP', 'ZEC']\n",
    "\n",
    "tickers = 'BTC'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_financials = load_financial_data(filepath = 'data/top20_aggre_price_reduced.csv', start_date = '2017-07-28', end_date = '2018-07-27', tickers = tickers)\n",
    "df_sentiment = load_sentiment_data(filepath = 'data/BTC_sentiment_aggr_shifted.csv', start_date = '2017-07-28', end_date = '2018-07-27')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the data\n",
    "df_merged = merge_sentiment_financials(df_financials, df_sentiment)\n",
    "df_merged.head(5)\n",
    "# Remove retweets and favorites (for now)\n",
    "#df_merged = df_merged.drop(['retweets', 'favorites'], axis = 1)\n",
    "\n",
    "# Fill the missing values for amount_of_tweets with the ffill method\n",
    "#df_merged['amount_of_tweets'] = df_merged['amount_of_tweets'].replace(to_replace=0, method = 'ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare for only 1/-1 for sink/fall of financials\n",
    "df_merged = df_merged.drop(['retweets', 'favorites'], axis = 1)\n",
    "df_merged['BTC'] = df_merged['BTC']-df_merged['BTC'].shift()\n",
    "df_merged['BTC'] = np.sign(df_merged['BTC'])\n",
    "df_merged.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get different values for BTC (log, diff, combination)\n",
    "\n",
    "# Diff\n",
    "df_merged['BTC_diff'] = df_merged['BTC']-df_merged['BTC'].shift()\n",
    "\n",
    "\n",
    "# Log\n",
    "df_merged['BTC_log']= np.log(df_merged['BTC'])\n",
    "\n",
    "# Diff of log\n",
    "df_merged['BTC_log_diff'] = df_merged['BTC_log']-df_merged['BTC_log'].shift()\n",
    "\n",
    "# Drop empty rows which were created through diff\n",
    "df_merged.dropna(inplace = True)\n",
    "\n",
    "# Make financial data binary (rise: 1/not rise: 0)\n",
    "df_merged['BTC_bin'] = np.sign(df_merged['BTC_diff'])\n",
    "df_merged['BTC_bin'] = df_merged['BTC_bin'].replace(to_replace = -1, value = 0)\n",
    "\n",
    "#Fill missing values with the ffill method\n",
    "df_merged['amount_of_tweets'] = df_merged['amount_of_tweets'].replace(to_replace=0, method = 'ffill')\n",
    "df_merged['sentiment'] = df_merged['sentiment'].replace(to_replace=0, method = 'ffill')\n",
    "df_merged['weighted_sentiment'] = df_merged['weighted_sentiment'].replace(to_replace=0, method = 'ffill')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augmented Dicky Fuller Test for Stationarity\n",
    "\n",
    "def test_stationarity(x, name):\n",
    "\n",
    "\n",
    "    #Determing rolling statistics\n",
    "    rolmean = x.rolling(window=22,center=False).mean()\n",
    "\n",
    "    rolstd = x.rolling(window=12,center=False).std()\n",
    "    \n",
    "    #Plot rolling statistics:\n",
    "    orig = plot.plot(x, color='blue',label='Original')\n",
    "    mean = plot.plot(rolmean, color='red', label='Rolling Mean')\n",
    "    std = plot.plot(rolstd, color='black', label = 'Rolling Std')\n",
    "    plot.legend(loc='best')\n",
    "    plot.title('Rolling Mean & Standard Deviation of the ' + name)\n",
    "    plot.show(block=False)\n",
    "    \n",
    "    #Perform Dickey Fuller test    \n",
    "    result=adfuller(x)\n",
    "    print('ADF Stastistic: %f'%result[0])\n",
    "    print('p-value: %f'%result[1])\n",
    "    pvalue=result[1]\n",
    "    for key,value in result[4].items():\n",
    "         if result[0]>value:\n",
    "            print(\"The graph is non stationery\")\n",
    "            break\n",
    "         else:\n",
    "            print(\"The graph is stationery\")\n",
    "            break;\n",
    "    print('Critical values:')\n",
    "    for key,value in result[4].items():\n",
    "        print('\\t%s: %.3f ' % (key, value))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test all values for stationarity individually\n",
    "\n",
    "stationarity_sentiment = test_stationarity(df_merged['sentiment'], 'sentiment')\n",
    "stationarity_amount = test_stationarity(df_merged['amount_of_tweets'], 'amount of tweets')\n",
    "stationarity_retweets = test_stationarity(df_merged['retweets'], 'amount of retweets')\n",
    "stationarity_favorites = test_stationarity(df_merged['favorites'], 'amount of favorites')\n",
    "stationarity_financials = test_stationarity(df_merged['BTC'], 'value of BTC')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since everything but the financial value is stationary at the the 5% value, we only have to modify the financial value\n",
    "df_merged['BTC']=np.log(df_merged['BTC'])\n",
    "\n",
    "# Retest for stationarity\n",
    "stationarity_financials = test_stationarity(df_merged['BTC'], 'value of BTC')\n",
    "\n",
    "# Still not stationary. therefore we will have to take tests which use the difference of the values (i.e. ARIMA instead of ARMA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking stationarity: All is good since the eigenvalues are <1\n",
    "coint_johansen(df_merged,-1,1).eig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_relevant = df_merged[['BTC', 'weighted_sentiment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make train/test split\n",
    "size = int(len(df_relevant)*0.9)\n",
    "\n",
    "# Divide into train and test\n",
    "train_var, test_var = df_relevant[0:size], df_relevant[size:len(df_relevant)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test VARMAX for 4 inputs\n",
    "history = train_var.values\n",
    "predictions = list()\n",
    "originals = list()\n",
    "error_list = list()\n",
    "\n",
    "# Creat empty Data Frame for output\n",
    "evaluation = pd.DataFrame(index=range(0,len(test_var)), columns=[['pred', 'exp', 'error %']])\n",
    "\n",
    "# Iterate over all days until day x\n",
    "for t in range(len(test_var)):\n",
    "    \n",
    "    # Define and fit model\n",
    "    model = VARMAX(history, order =(1,1))\n",
    "    model_fit = model.fit()\n",
    "    \n",
    "    # Predict bitcoin value for day x+1\n",
    "    output = model_fit.forecast(steps=1)\n",
    "    pred_value = output[0,4]\n",
    "    \n",
    "    # Define the other factors for the output\n",
    "    original_value = test_var.iloc[t, 4]  \n",
    "    error = ((abs(pred_value - original_value)) / original_value) * 100\n",
    "\n",
    "    # Print output for day x+1\n",
    "    print('predicted = %f,   expected = %f,   error = %f ' % (pred_value, original_value, error), '%')\n",
    "    \n",
    "    # Lists for plots\n",
    "    error_list.append(error)\n",
    "    predictions.append(float(pred_value))\n",
    "    originals.append(float(original_value))\n",
    "\n",
    "    # Add the values for day x+1 to the output dataframe\n",
    "    evaluation.iloc[t][0] = pred_value\n",
    "    evaluation.iloc[t][1] = original_value\n",
    "    evaluation.iloc[t][2] = error\n",
    "    \n",
    "    # fill newest row in history to adjust data for next iteration\n",
    "    history = np.concatenate((history,test_var.values[t,:].reshape(1,5)))\n",
    "    \n",
    "    #delete output to make sure that it doesnt stick for other evaluations\n",
    "    del output\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test VARMAX for 2 input variables \n",
    "history = train_var.values\n",
    "predictions = list()\n",
    "originals = list()\n",
    "error_list = list()\n",
    "\n",
    "# Creat empty Data Frame for output\n",
    "evaluation = pd.DataFrame(index=range(0,len(test_var)), columns=[['pred', 'exp', 'error %']])\n",
    "\n",
    "# Iterate over all days until day x\n",
    "for t in range(len(test_var)):\n",
    "    \n",
    "    # Define and fit model\n",
    "    model = VARMAX(history, order =(1,1))\n",
    "    model_fit = model.fit()\n",
    "    \n",
    "    # Predict bitcoin value for day x+1\n",
    "    output = model_fit.forecast(steps=1)\n",
    "    pred_value = output[0,1]\n",
    "    \n",
    "    # Define the other factors for the output\n",
    "    original_value = test_var.iloc[t, 1]  \n",
    "    error = ((abs(pred_value - original_value)) / original_value) * 100\n",
    "\n",
    "    # Print output for day x+1\n",
    "    print('predicted = %f,   expected = %f,   error = %f ' % (pred_value, original_value, error), '%')\n",
    "    \n",
    "    # Lists for plots\n",
    "    error_list.append(error)\n",
    "    predictions.append(float(pred_value))\n",
    "    originals.append(float(original_value))\n",
    "\n",
    "    # Add the values for day x+1 to the output dataframe\n",
    "    evaluation.iloc[t][0] = pred_value\n",
    "    evaluation.iloc[t][1] = original_value\n",
    "    evaluation.iloc[t][2] = error\n",
    "    \n",
    "    # fill newest row in history to adjust data for next iteration\n",
    "    history = np.concatenate((history,test_var.values[t,:].reshape(1,2)))\n",
    "    \n",
    "    #delete output to make sure that it doesnt stick for other evaluations\n",
    "    del output\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate overall mean error after all iterations\n",
    "print('\\n Mean Error in Predicting Test Case Articles : %f ' % (sum(error_list)/float(len(error_list))), '%')\n",
    "\n",
    "# Plot the Expected Vs Predicted Forecasting\n",
    "plot.figure(figsize=(8, 6))\n",
    "test_day = [t for t in range(len(test_var))]\n",
    "labels={'Orginal','Predicted'}\n",
    "plot.plot(test_day, predictions, color= 'green')\n",
    "plot.plot(test_day, originals, color = 'orange')\n",
    "plot.title('Expected Vs Predicted: Multivariat VARMAX')\n",
    "plot.xlabel('Hours')\n",
    "plot.ylabel('Closing Price')\n",
    "plot.legend(labels)\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(evaluation['error %'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_cleaned = evaluation.drop([238, 239, 246, 266, 378])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Sentiment Env)",
   "language": "python",
   "name": "sentiment_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
